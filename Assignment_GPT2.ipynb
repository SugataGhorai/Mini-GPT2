{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SugataGhorai/Mini-GPT2/blob/main/Assignment_GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liPgAPtwpqIi"
      },
      "source": [
        "# Question No.:1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKROqFOxpqIj",
        "outputId": "dd4a7b42-8818-4019-90da-d435dfad14e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/neelnanda-io/Easy-Transformer.git@clean-transformer-demo\n",
            "  Cloning https://github.com/neelnanda-io/Easy-Transformer.git (to revision clean-transformer-demo) to /tmp/pip-req-build-gv77rive\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/Easy-Transformer.git /tmp/pip-req-build-gv77rive\n",
            "  Running command git checkout -b clean-transformer-demo --track origin/clean-transformer-demo\n",
            "  Switched to a new branch 'clean-transformer-demo'\n",
            "  Branch 'clean-transformer-demo' set up to track remote branch 'clean-transformer-demo' from 'origin'.\n",
            "  Resolved https://github.com/neelnanda-io/Easy-Transformer.git to commit 1f25219e631aeb478d17075d47274db32c874e88\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (2.15.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (4.66.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (1.5.3)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (0.16.1)\n",
            "Requirement already satisfied: fancy_einsum in /usr/local/lib/python3.10/dist-packages (from easy-transformer==0.1.0) (0.0.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (0.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets->easy-transformer==0.1.0) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->easy-transformer==0.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->easy-transformer==0.1.0) (2023.3.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->easy-transformer==0.1.0) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->easy-transformer==0.1.0) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->easy-transformer==0.1.0) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->easy-transformer==0.1.0) (0.4.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (3.1.40)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (1.39.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->easy-transformer==0.1.0) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->easy-transformer==0.1.0) (1.16.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (4.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb->easy-transformer==0.1.0) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easy-transformer==0.1.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easy-transformer==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->easy-transformer==0.1.0) (5.0.1)\n",
            "Requirement already satisfied: fancy_einsum in /usr/local/lib/python3.10/dist-packages (0.0.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%pip install git+https://github.com/neelnanda-io/Easy-Transformer.git@clean-transformer-demo\n",
        "%pip install fancy_einsum\n",
        "%pip install einops\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQWNo4cZpqIk"
      },
      "outputs": [],
      "source": [
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "from dataclasses import dataclass\n",
        "from easy_transformer import EasyTransformer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import math\n",
        "from easy_transformer.utils import get_corner, gelu_new, tokenize_and_concatenate\n",
        "import tqdm.auto as tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uW4a4I8hpqIk",
        "outputId": "5923352f-0aac-4067-ed4a-c842f1dc6029",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving model to device:  cpu\n",
            "Finished loading pretrained model gpt2-small into EasyTransformer!\n"
          ]
        }
      ],
      "source": [
        "reference_gpt2 = EasyTransformer.from_pretrained(\"gpt2-small\", fold_ln=False, center_unembed=False, center_writing_weights=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zz1jHFUGpqIl",
        "outputId": "c011c348-2e71-4e2e-b258-944250072358",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('!', 0), ('\"', 1), ('#', 2), ('$', 3), ('%', 4), ('&', 5), (\"'\", 6), ('(', 7), (')', 8), ('*', 9), ('+', 10), (',', 11), ('-', 12), ('.', 13), ('/', 14), ('0', 15), ('1', 16), ('2', 17), ('3', 18), ('4', 19)]\n",
            "\n",
            "[('ľ', 250), ('Ŀ', 251), ('ŀ', 252), ('Ł', 253), ('ł', 254), ('Ń', 255), ('Ġt', 256), ('Ġa', 257), ('he', 258), ('in', 259), ('re', 260), ('on', 261), ('Ġthe', 262), ('er', 263), ('Ġs', 264), ('at', 265), ('Ġw', 266), ('Ġo', 267), ('en', 268), ('Ġc', 269)]\n",
            "\n",
            "[('Ġprodu', 990), ('Ġstill', 991), ('led', 992), ('ah', 993), ('Ġhere', 994), ('Ġworld', 995), ('Ġthough', 996), ('Ġnum', 997), ('arch', 998), ('imes', 999), ('ale', 1000), ('ĠSe', 1001), ('ĠIf', 1002), ('//', 1003), ('ĠLe', 1004), ('Ġret', 1005), ('Ġref', 1006), ('Ġtrans', 1007), ('ner', 1008), ('ution', 1009)]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sorted_vocab = sorted(list(reference_gpt2.tokenizer.vocab.items()), key=lambda n:n[1])\n",
        "print(sorted_vocab[:20])\n",
        "print()\n",
        "print(sorted_vocab[250:270])\n",
        "print()\n",
        "print(sorted_vocab[990:1010])\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhv2Sfn3pqIm",
        "outputId": "67db2768-aa47-4c5e-8001-4e0d73cd0474",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50256, 15354,   257,  1573,  6140,   351,   257,  3139,   393,  2272,\n",
            "          6067,     0]])\n",
            "tensor([[15354,   257,  1573,  6140,   351,   257,  3139,   393,  2272,  6067,\n",
            "             0]])\n"
          ]
        }
      ],
      "source": [
        "print(reference_gpt2.to_tokens(\"Whether a word begins with a capital or space matters!\"))\n",
        "print(reference_gpt2.to_tokens(\"Whether a word begins with a capital or space matters!\", prepend_bos=False))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokens\n",
        "logits, cache = reference_gpt2.run_with_cache(tokens)\n",
        "print(logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVyg1jiuOp_-",
        "outputId": "e9d6383f-8454-4001-969c-46a43372813c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 35, 50257])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMN_VW1YpqIn",
        "outputId": "294af4b0-0e64-463d-86e7-41a29d30f996",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 35, 50257])\n",
            "torch.Size([1, 35, 50257])\n"
          ]
        }
      ],
      "source": [
        "log_probs = logits.log_softmax(dim=-1)\n",
        "probs = logits.log_softmax(dim=-1)\n",
        "print(log_probs.shape)\n",
        "print(probs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0707KBmjpqIu"
      },
      "source": [
        "Key:\n",
        "```\n",
        "batch = 1\n",
        "position = 35\n",
        "d_model = 768\n",
        "n_heads = 12\n",
        "n_layers = 12\n",
        "d_mlp = 3072 (4 * d_model)\n",
        "d_head = 64 (d_model / n_heads)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIGsKLWZpqIu",
        "outputId": "5f2a1daf-0e60-4910-df1c-d43a3f719a48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hook_embed torch.Size([1, 35, 768])\n",
            "hook_pos_embed torch.Size([1, 35, 768])\n",
            "blocks.0.hook_resid_pre torch.Size([1, 35, 768])\n",
            "blocks.0.ln1.hook_scale torch.Size([1, 35, 1])\n",
            "blocks.0.ln1.hook_normalized torch.Size([1, 35, 768])\n",
            "blocks.0.attn.hook_q torch.Size([1, 35, 12, 64])\n",
            "blocks.0.attn.hook_k torch.Size([1, 35, 12, 64])\n",
            "blocks.0.attn.hook_v torch.Size([1, 35, 12, 64])\n",
            "blocks.0.attn.hook_attn_scores torch.Size([1, 12, 35, 35])\n",
            "blocks.0.attn.hook_attn torch.Size([1, 12, 35, 35])\n",
            "blocks.0.attn.hook_z torch.Size([1, 35, 12, 64])\n",
            "blocks.0.hook_attn_out torch.Size([1, 35, 768])\n",
            "blocks.0.hook_resid_mid torch.Size([1, 35, 768])\n",
            "blocks.0.ln2.hook_scale torch.Size([1, 35, 1])\n",
            "blocks.0.ln2.hook_normalized torch.Size([1, 35, 768])\n",
            "blocks.0.mlp.hook_pre torch.Size([1, 35, 3072])\n",
            "blocks.0.mlp.hook_post torch.Size([1, 35, 3072])\n",
            "blocks.0.hook_mlp_out torch.Size([1, 35, 768])\n",
            "blocks.0.hook_resid_post torch.Size([1, 35, 768])\n",
            "ln_final.hook_scale torch.Size([1, 35, 1])\n",
            "ln_final.hook_normalized torch.Size([1, 35, 768])\n"
          ]
        }
      ],
      "source": [
        "for activation_name, activation in cache.cache_dict.items():\n",
        "    # Only print for first layer\n",
        "    if \".0.\" in activation_name or \"blocks\" not in activation_name:\n",
        "        print(activation_name, activation.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-9bkxvlpqIu"
      },
      "outputs": [],
      "source": [
        "for name, param in reference_gpt2.named_parameters():\n",
        "    # Only print for first layer\n",
        "    if \".0.\" in name or \"blocks\" not in name:\n",
        "        print(name, param.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsCn3vgupqIv",
        "outputId": "04468244-58c2-40d6-a4a0-7226eceb834b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EasyTransformerConfig(n_layers=12, d_model=768, n_ctx=1024, d_head=64, model_name='gpt2-small', n_heads=12, d_mlp=3072, act_fn='gelu_new', d_vocab=50257, eps=1e-05, use_attn_result=False, use_attn_scale=True, use_local_attn=False, model_family='gpt2', checkpoint=None, tokenizer_name='gpt2', window_size=None, attn_types=None, init_mode='gpt2', normalization_type='LN', device='cpu', attention_dir='causal', attn_only=False, seed=42, initializer_range=0.02886751345948129, init_weights=False, scale_attn_by_inverse_layer_idx=False, positional_embedding_type='standard', final_rms=False, d_vocab_out=50257, parallel_attn_mlp=False, rotary_dim=64, dtype=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "# As a reference - note there's a lot of stuff we don't care about in here, to do with library internals or other architectures\n",
        "print(reference_gpt2.cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_uVn1DApqIv"
      },
      "source": [
        "We define a stripped down config for our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73l1qrPvpqIv",
        "outputId": "d93bfad3-f068-468e-d47c-527b7a812fa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config(d_model=768, debug=True, layer_norm_eps=1e-05, d_vocab=50257, init_range=0.02, n_ctx=1024, d_head=64, d_mlp=3072, n_heads=12, n_layers=12)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    d_model: int = 768\n",
        "    debug: bool = True\n",
        "    layer_norm_eps: float = 1e-5\n",
        "    d_vocab: int = 50257\n",
        "    init_range: float = 0.02\n",
        "    n_ctx: int = 1024\n",
        "    d_head: int = 64\n",
        "    d_mlp: int = 3072\n",
        "    n_heads: int = 12\n",
        "    n_layers: int = 12\n",
        "\n",
        "cfg = Config()\n",
        "print(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0EevbklpqIv"
      },
      "outputs": [],
      "source": [
        "def rand_float_test(cls, shape):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg)\n",
        "    random_input = torch.randn(shape)\n",
        "    print(\"Input shape:\", random_input.shape)\n",
        "    output = layer(random_input)\n",
        "    print(\"Output shape:\", output.shape)\n",
        "    print()\n",
        "    return output\n",
        "\n",
        "def rand_int_test(cls, shape):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg)\n",
        "    random_input = torch.randint(100, 1000, shape)\n",
        "    print(\"Input shape:\", random_input.shape)\n",
        "    output = layer(random_input)\n",
        "    print(\"Output shape:\", output.shape)\n",
        "    print()\n",
        "    return output\n",
        "\n",
        "def load_gpt2_test(cls, gpt2_layer, input_name, cache_dict=cache.cache_dict):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg)\n",
        "    layer.load_state_dict(gpt2_layer.state_dict(), strict=False)\n",
        "    # Allow inputs of strings or tensors\n",
        "    if isinstance(input_name, str):\n",
        "        reference_input = cache_dict[input_name]\n",
        "    else:\n",
        "        reference_input = input_name\n",
        "    print(\"Input shape:\", reference_input.shape)\n",
        "    output = layer(reference_input)\n",
        "    print(\"Output shape:\", output.shape)\n",
        "    reference_output = gpt2_layer(reference_input)\n",
        "    print(\"Reference output shape:\", reference_output.shape)\n",
        "\n",
        "    comparison = torch.isclose(output, reference_output, atol=1e-4, rtol=1e-3)\n",
        "    print(f\"{comparison.sum()/comparison.numel():.2%} of the values are correct\")\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNzdgZcdpqIw"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.w = nn.Parameter(torch.ones(cfg.d_model))\n",
        "        self.b = nn.Parameter(torch.zeros(cfg.d_model))\n",
        "\n",
        "    def forward(self, residual):\n",
        "        # residual: [batch, position, d_model]\n",
        "        if self.cfg.debug: print(\"Residual:\", residual.shape)\n",
        "        residual = residual - einops.reduce(residual, \"batch position d_model -> batch position 1\", \"mean\")\n",
        "        # Calculate the variance, square root it. Add in an epsilon to prevent divide by zero.\n",
        "        scale = (einops.reduce(residual.pow(2), \"batch position d_model -> batch position 1\", \"mean\") + cfg.layer_norm_eps).sqrt()\n",
        "        normalized = residual / scale\n",
        "        normalized = normalized * self.w + self.b\n",
        "        if self.cfg.debug: print(\"Normalized:\", residual.shape)\n",
        "        return normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxKA0ikspqIw",
        "outputId": "2b64d85b-28a0-4d9a-eebe-d92e6aa301f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        }
      ],
      "source": [
        "_ = rand_float_test(LayerNorm, [2, 4, 768])\n",
        "_ = load_gpt2_test(LayerNorm, reference_gpt2.ln_final, \"blocks.11.hook_resid_post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06gGNw9mpqIw",
        "outputId": "ad27b480-4800-45c1-e00c-de51d947f342",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Tokens: torch.Size([2, 4])\n",
            "Embeddings: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35])\n",
            "Tokens: torch.Size([1, 35])\n",
            "Embeddings: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0514, -0.0277,  0.0499,  ...,  0.0070,  0.1552,  0.1207],\n",
              "         [ 0.1474, -0.0959,  0.1430,  ...,  0.1030, -0.0625, -0.1131],\n",
              "         [ 0.1596, -0.1249,  0.1148,  ...,  0.2558,  0.0196,  0.0145],\n",
              "         ...,\n",
              "         [-0.0393,  0.0050,  0.0421,  ..., -0.0477,  0.0670, -0.0471],\n",
              "         [-0.1488,  0.1519,  0.0056,  ..., -0.3107,  0.2073,  0.0377],\n",
              "         [-0.1101, -0.0393,  0.0331,  ..., -0.1364,  0.0151,  0.0453]]],\n",
              "       grad_fn=<IndexBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "class Embed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_E = nn.Parameter(torch.empty((cfg.d_vocab, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        # tokens: [batch, position]\n",
        "        if self.cfg.debug: print(\"Tokens:\", tokens.shape)\n",
        "        embed = self.W_E[tokens, :] # [batch, position, d_model]\n",
        "        if self.cfg.debug: print(\"Embeddings:\", embed.shape)\n",
        "        return embed\n",
        "\n",
        "rand_int_test(Embed, [2, 4])\n",
        "load_gpt2_test(Embed, reference_gpt2.embed, tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-lL0AsepqIw"
      },
      "source": [
        "## Positional Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6gupiwkqpqIw",
        "outputId": "9409ea81-5643-489c-9e47-c4135c521a6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Tokens: torch.Size([2, 4])\n",
            "pos_embed: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35])\n",
            "Tokens: torch.Size([1, 35])\n",
            "pos_embed: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.8821e-02, -1.9742e-01,  4.0267e-03,  ..., -4.3044e-02,\n",
              "           2.8267e-02,  5.4490e-02],\n",
              "         [ 2.3959e-02, -5.3792e-02, -9.4879e-02,  ...,  3.4170e-02,\n",
              "           1.0172e-02, -1.5573e-04],\n",
              "         [ 4.2161e-03, -8.4764e-02,  5.4515e-02,  ...,  1.9745e-02,\n",
              "           1.9325e-02, -2.1424e-02],\n",
              "         ...,\n",
              "         [ 4.6277e-04,  2.3037e-02,  4.1227e-02,  ..., -1.9287e-03,\n",
              "          -2.3037e-03, -4.3189e-03],\n",
              "         [-2.7136e-03,  2.1724e-02,  3.9675e-02,  ...,  4.2048e-04,\n",
              "          -4.8160e-03, -9.2252e-04],\n",
              "         [ 6.6815e-03,  2.0595e-02,  3.6596e-02,  ..., -9.5090e-04,\n",
              "          -3.2512e-03, -9.6509e-04]]], grad_fn=<ExpandBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ],
      "source": [
        "class PosEmbed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_pos = nn.Parameter(torch.empty((cfg.n_ctx, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        # tokens: [batch, position]\n",
        "        if self.cfg.debug: print(\"Tokens:\", tokens.shape)\n",
        "        pos_embed = self.W_pos[:tokens.size(1), :] # [position, d_model]\n",
        "        pos_embed = einops.repeat(pos_embed, \"position d_model -> batch position d_model\", batch=tokens.size(0))\n",
        "        if self.cfg.debug: print(\"pos_embed:\", pos_embed.shape)\n",
        "        return pos_embed\n",
        "\n",
        "rand_int_test(PosEmbed, [2, 4])\n",
        "load_gpt2_test(PosEmbed, reference_gpt2.pos_embed, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uO_IIQY6pqIw"
      },
      "source": [
        "## Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9X38-TMIpqIx",
        "outputId": "a1566de4-13e3-425c-c5c6-5a7ae1df5dcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 7.9663e-01,  1.6985e-02,  3.4781e-02,  ...,  3.3120e-02,\n",
              "          -2.3129e-02,  1.8103e-01],\n",
              "         [ 1.3167e-03,  1.5750e-01, -1.4059e-01,  ..., -8.1997e-03,\n",
              "           5.3075e-03,  1.3511e-01],\n",
              "         [ 8.9738e-02, -7.2411e-01, -6.9866e-01,  ...,  5.5321e-02,\n",
              "           2.7958e-03,  9.0785e-02],\n",
              "         ...,\n",
              "         [-3.0286e-01,  4.9638e-02, -6.0990e-01,  ..., -3.7084e-02,\n",
              "          -4.9524e-04, -8.6008e-03],\n",
              "         [-1.0844e+00, -6.1457e-02,  2.2966e-01,  ..., -2.6688e-02,\n",
              "          -1.4368e-02,  3.3245e-02],\n",
              "         [ 3.7947e-01, -4.9886e-01,  2.6434e-01,  ..., -2.7894e-02,\n",
              "          -8.9028e-03,  4.8796e-02]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_Q = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
        "        self.b_Q = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.W_K = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
        "        self.b_K = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.W_V = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
        "        self.b_V = nn.Parameter(torch.zeros((cfg.n_heads, cfg.d_head)))\n",
        "\n",
        "        self.W_O = nn.Parameter(torch.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
        "        self.b_O = nn.Parameter(torch.zeros((cfg.d_model)))\n",
        "\n",
        "        self.register_buffer(\"IGNORE\", torch.tensor(-1e5, dtype=torch.float32))\n",
        "\n",
        "    def forward(self, normalized_resid_pre):\n",
        "        # normalized_resid_pre: [batch, position, d_model]\n",
        "        if self.cfg.debug: print(\"Normalized_resid_pre:\", normalized_resid_pre.shape)\n",
        "\n",
        "        q = einsum(\"batch query_pos d_model, n_heads d_model d_head -> batch query_pos n_heads d_head\", normalized_resid_pre, self.W_Q) + self.b_Q\n",
        "        k = einsum(\"batch key_pos d_model, n_heads d_model d_head -> batch key_pos n_heads d_head\", normalized_resid_pre, self.W_K) + self.b_K\n",
        "\n",
        "        attn_scores = einsum(\"batch query_pos n_heads d_head, batch key_pos n_heads d_head -> batch n_heads query_pos key_pos\", q, k)\n",
        "        attn_scores = attn_scores / math.sqrt(self.cfg.d_head)\n",
        "        attn_scores = self.apply_causal_mask(attn_scores)\n",
        "\n",
        "        pattern = attn_scores.softmax(dim=-1) # [batch, n_head, query_pos, key_pos]\n",
        "\n",
        "        v = einsum(\"batch key_pos d_model, n_heads d_model d_head -> batch key_pos n_heads d_head\", normalized_resid_pre, self.W_V) + self.b_V\n",
        "\n",
        "        z = einsum(\"batch n_heads query_pos key_pos, batch key_pos n_heads d_head -> batch query_pos n_heads d_head\", pattern, v)\n",
        "\n",
        "        attn_out = einsum(\"batch query_pos n_heads d_head, n_heads d_head d_model -> batch query_pos d_model\", z, self.W_O) + self.b_O\n",
        "        return attn_out\n",
        "\n",
        "    def apply_causal_mask(self, attn_scores):\n",
        "        # attn_scores: [batch, n_heads, query_pos, key_pos]\n",
        "        mask = torch.triu(torch.ones(attn_scores.size(-2), attn_scores.size(-1), device=attn_scores.device), diagonal=1).bool()\n",
        "        attn_scores.masked_fill_(mask, self.IGNORE)\n",
        "        return attn_scores\n",
        "\n",
        "rand_float_test(Attention, [2, 4, 768])\n",
        "load_gpt2_test(Attention, reference_gpt2.blocks[0].attn, cache[\"blocks.0.ln1.hook_normalized\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHn-4W5jpqIx"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kbazu2FrpqIx",
        "outputId": "e91e2207-52fd-4555-a248-c79fc94ae05f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "0.01% of the values are correct\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-140-ba015d8a2973>:6: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  nn.init.normal(self.W_in , std = self.cfg.init_range)\n",
            "<ipython-input-140-ba015d8a2973>:9: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  nn.init.normal(self.W_out , std = self.cfg.init_range)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 2.4749, -0.2070,  2.5430,  ..., -0.6799,  1.9317, -1.0080],\n",
              "         [ 3.0347, -0.2549,  3.1805,  ..., -0.8428,  2.3334, -1.2433],\n",
              "         [ 2.5416, -0.2118,  2.6213,  ..., -0.6994,  1.9812, -1.0375],\n",
              "         ...,\n",
              "         [ 3.5637, -0.3127,  3.7559,  ..., -0.9968,  2.6988, -1.4467],\n",
              "         [ 3.3573, -0.2890,  3.5335,  ..., -0.9366,  2.5568, -1.3689],\n",
              "         [ 3.7733, -0.3381,  3.9798,  ..., -1.0582,  2.8430, -1.5243]]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ],
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.cfg = cfg\n",
        "    self.W_in = nn.Parameter(torch.empty((cfg.d_model, cfg.d_mlp)))\n",
        "    nn.init.normal(self.W_in , std = self.cfg.init_range)\n",
        "    self.b_in = nn.Parameter(torch.zeros((cfg.d_mlp)))\n",
        "    self.W_out = nn.Parameter(torch.empty((cfg.d_mlp , cfg.d_model)))\n",
        "    nn.init.normal(self.W_out , std = self.cfg.init_range)\n",
        "    self.b_out = nn.Parameter(torch.zeros((cfg.d_model)))\n",
        "\n",
        "  def forward(self, normalized_resid_mid):\n",
        "    if cfg.debug:print(\"Normalized_resid_mid:\", normalized_resid_mid.shape)\n",
        "    pre = einsum(\"batch position D_model , d_model d_mlp -> batch position d_mlp:\", normalized_resid_mid, self.W_in) + self.b_in\n",
        "    post = gelu_new(pre)\n",
        "    mlp_out = einsum(\"batch position d_mlp , d_mlp d_model -> batch position d_model\", post,self.W_out )+self.b_out\n",
        "    return mlp_out\n",
        "\n",
        "rand_float_test(MLP, [2, 4, 768])\n",
        "load_gpt2_test(MLP, reference_gpt2.blocks[0].attn, cache[\"blocks.0.ln1.hook_normalized\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y807sWQCpqIy"
      },
      "source": [
        "## Transformer Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_nRsnrdpqIy",
        "outputId": "9985fa73-c177-42cb-dc52-f97be87aae70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768])\n",
            "0.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-140-ba015d8a2973>:6: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  nn.init.normal(self.W_in , std = self.cfg.init_range)\n",
            "<ipython-input-140-ba015d8a2973>:9: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  nn.init.normal(self.W_out , std = self.cfg.init_range)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-120.7454,  -54.3913,   31.7342,  ...,  -19.3543,  -68.2184,\n",
              "            -9.3758],\n",
              "         [ -26.6878,  -53.6176,  -79.0066,  ...,   93.5618,   63.8590,\n",
              "            58.7641],\n",
              "         [  -8.1097,   -4.3426,    1.7874,  ...,   -1.3203,   -5.0281,\n",
              "            -1.0259],\n",
              "         ...,\n",
              "         [ -10.0225,   -3.9095,    1.9514,  ...,   -1.8564,   -5.6645,\n",
              "            -1.1978],\n",
              "         [ -34.3902,  -14.4560,    8.7235,  ...,   -5.7804,  -18.4864,\n",
              "            -2.7960],\n",
              "         [-124.9740,  -56.3269,   32.9491,  ...,  -20.0940,  -70.4331,\n",
              "            -9.9279]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "\n",
        "        self.ln1 = LayerNorm(cfg)\n",
        "        self.attn = Attention(cfg)\n",
        "        self.ln2 = LayerNorm(cfg)\n",
        "        self.mlp = MLP(cfg)\n",
        "\n",
        "    def forward(self, resid_pre):\n",
        "        # resid_pre [batch, position, d_model]\n",
        "        normalized_resid_pre = self.ln1(resid_pre)\n",
        "        attn_out = self.attn(normalized_resid_pre)\n",
        "        resid_mid = resid_pre + attn_out\n",
        "\n",
        "        normalized_resid_mid = self.ln2(resid_mid)\n",
        "        mlp_out = self.mlp(normalized_resid_mid)\n",
        "        resid_post = resid_mid + mlp_out\n",
        "        return resid_post\n",
        "rand_float_test(TransformerBlock, [2, 4, 768])\n",
        "load_gpt2_test(TransformerBlock, reference_gpt2.blocks[0], cache[\"resid_pre\", 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AnSQo8ApqIy"
      },
      "source": [
        "## Unembedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKUHa1INpqIy",
        "outputId": "f9b76943-ee3b-4f69-e7d6-fc95677e7c0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Normalized_resid_final: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Normalized_resid_final: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 50257])\n",
            "Reference output shape: torch.Size([1, 35, 50257])\n",
            "100.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ -43.4317,  -39.8364,  -43.0660,  ...,  -54.0877,  -54.3452,\n",
              "           -42.3644],\n",
              "         [-128.0392, -127.9936, -130.7010,  ..., -136.7123, -129.9261,\n",
              "          -129.3966],\n",
              "         [-119.8521, -121.0064, -123.8820,  ..., -128.5181, -126.6028,\n",
              "          -121.9060],\n",
              "         ...,\n",
              "         [-112.9815, -112.7748, -117.0634,  ..., -121.2914, -117.6574,\n",
              "          -114.5005],\n",
              "         [ -98.6724, -104.4888, -108.7361,  ..., -118.3552, -113.8766,\n",
              "          -106.3604],\n",
              "         [-126.8284, -128.9596, -128.3941,  ..., -140.1970, -138.5883,\n",
              "          -122.3697]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "class Unembed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_U = nn.Parameter(torch.empty((cfg.d_model, cfg.d_vocab)))\n",
        "        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n",
        "        self.b_U = nn.Parameter(torch.zeros((cfg.d_vocab), requires_grad=False))\n",
        "\n",
        "    def forward(self, normalized_resid_final):\n",
        "        # normalized_resid_final [batch, position, d_model]\n",
        "        if self.cfg.debug: print(\"Normalized_resid_final:\", normalized_resid_final.shape)\n",
        "        logits = einsum(\"batch position d_model, d_model d_vocab -> batch position d_vocab\", normalized_resid_final, self.W_U) + self.b_U\n",
        "        return logits\n",
        "\n",
        "rand_float_test(Unembed, [2, 4, 768])\n",
        "load_gpt2_test(Unembed, reference_gpt2.unembed, cache[\"ln_final.hook_normalized\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df7_WieppqIy"
      },
      "source": [
        "## Full Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PpH9dOlpqIy",
        "outputId": "198c4677-a625-4bc1-cf17-4b06cda83b8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-140-ba015d8a2973>:6: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  nn.init.normal(self.W_in , std = self.cfg.init_range)\n",
            "<ipython-input-140-ba015d8a2973>:9: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  nn.init.normal(self.W_out , std = self.cfg.init_range)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Tokens: torch.Size([2, 4])\n",
            "Embeddings: torch.Size([2, 4, 768])\n",
            "Tokens: torch.Size([2, 4])\n",
            "pos_embed: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_pre: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_mid: torch.Size([2, 4, 768])\n",
            "Residual: torch.Size([2, 4, 768])\n",
            "Normalized: torch.Size([2, 4, 768])\n",
            "Normalized_resid_final: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "\n",
            "Input shape: torch.Size([1, 35])\n",
            "Tokens: torch.Size([1, 35])\n",
            "Embeddings: torch.Size([1, 35, 768])\n",
            "Tokens: torch.Size([1, 35])\n",
            "pos_embed: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_pre: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 35, 768])\n",
            "Residual: torch.Size([1, 35, 768])\n",
            "Normalized: torch.Size([1, 35, 768])\n",
            "Normalized_resid_final: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 50257])\n",
            "Reference output shape: torch.Size([1, 35, 50257])\n",
            "0.00% of the values are correct\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-19.8267, -20.0863, -22.1580,  ..., -27.9483, -27.7606, -20.4149],\n",
              "         [-20.4406, -20.7046, -22.6788,  ..., -27.6188, -27.5927, -20.9905],\n",
              "         [-18.8323, -19.0597, -21.2166,  ..., -26.7200, -26.6972, -19.4153],\n",
              "         ...,\n",
              "         [-18.8237, -19.0512, -21.2045,  ..., -26.7016, -26.6773, -19.4049],\n",
              "         [-19.0212, -19.2651, -21.3906,  ..., -26.9121, -26.8596, -19.6095],\n",
              "         [-19.6317, -19.8904, -21.9657,  ..., -27.7592, -27.5608, -20.2095]]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ],
      "source": [
        "class DemoTransformer(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.embed = Embed(cfg)\n",
        "        self.pos_embed = PosEmbed(cfg)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
        "        self.ln_final = LayerNorm(cfg)\n",
        "        self.unembed = Unembed(cfg)\n",
        "\n",
        "    def forward(self, tokens):\n",
        "        # tokens [batch, position]\n",
        "        embed = self.embed(tokens)\n",
        "        pos_embed = self.pos_embed(tokens)\n",
        "        residual = embed + pos_embed\n",
        "        for block in self.blocks:\n",
        "            residual = block(residual)\n",
        "        normalized_resid_final = self.ln_final(residual)\n",
        "        logits = self.unembed(normalized_resid_final)\n",
        "        # logits have shape [batch, position, logits]\n",
        "        return logits\n",
        "\n",
        "rand_int_test(DemoTransformer, [2, 4])\n",
        "load_gpt2_test(DemoTransformer, reference_gpt2, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziceXpL4pqIy"
      },
      "source": [
        "# Try it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toOoEqQzpqIy",
        "outputId": "43b94c76-5f60-45d9-8139-9bfd24ac1171",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-140-ba015d8a2973>:6: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  nn.init.normal(self.W_in , std = self.cfg.init_range)\n",
            "<ipython-input-140-ba015d8a2973>:9: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
            "  nn.init.normal(self.W_out , std = self.cfg.init_range)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=[], unexpected_keys=['blocks.0.attn.mask', 'blocks.1.attn.mask', 'blocks.2.attn.mask', 'blocks.3.attn.mask', 'blocks.4.attn.mask', 'blocks.5.attn.mask', 'blocks.6.attn.mask', 'blocks.7.attn.mask', 'blocks.8.attn.mask', 'blocks.9.attn.mask', 'blocks.10.attn.mask', 'blocks.11.attn.mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ],
      "source": [
        "demo_gpt2 = DemoTransformer(Config(debug=False))\n",
        "demo_gpt2.load_state_dict(reference_gpt2.state_dict(), strict=False)\n",
        "#demo_gpt2.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bY11RYNpqIz"
      },
      "source": [
        "Take a test string. Let's calculate the loss!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEAbw3-JpqIz"
      },
      "outputs": [],
      "source": [
        "test_string = \"\"\"Mini scule is a species of microhylid frog endemic to Madagascar that was described in 2019. The scientific name of the species refers to its size, being a pun on the word minuscule. It is very small, measuring only 8.4 to 10.8 mm (0.33 to 0.43 in) in snout–vent length. It has bronze underparts with a brown groin and back of the thigh, cream upperparts with brown flecking, a dark brown side of the head, and a red iris. On the hind feet, the first toe is absent and the second and fifth toes are strongly reduced. The frog is known only from the Sainte Luce Reserve, where it inhabits areas with deep leaf litter near semi-permanent water bodies. Specimens of frogs from Mandena, the Vohimena mountains, the southern Anosy Mountains, and Tsitongambarika may also be of this species. Along with Mini mum and Mini ature, the other two species in its genus, it received media attention when first described due to the wordplay in its scientific name. (Full article...)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lUSZJR0pqIz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bf4a93c-cc73-47b5-906a-0de98447d859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized_resid_mid: torch.Size([1, 237, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 237, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 237, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 237, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 237, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 237, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 237, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 237, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 237, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 237, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 237, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 237, 768])\n"
          ]
        }
      ],
      "source": [
        "test_tokens = reference_gpt2.to_tokens(test_string)\n",
        "demo_logits = demo_gpt2(test_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2RpoGK0pqIz",
        "outputId": "4fba3d03-93b8-47af-fd2c-095a953517ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(7.9293, grad_fn=<NegBackward0>)\n",
            "Loss as average prob tensor(0.0004, grad_fn=<ExpBackward0>)\n",
            "Loss as 'uniform over this many variables' tensor(2777.6125, grad_fn=<ExpBackward0>)\n",
            "Uniform loss over the vocab 10.82490511970208\n"
          ]
        }
      ],
      "source": [
        "def lm_cross_entropy_loss(logits, tokens):\n",
        "    # Measure next token loss\n",
        "    # Logits have shape [batch, position, d_vocab]\n",
        "    # Tokens have shape [batch, position]\n",
        "    log_probs = logits.log_softmax(dim=-1)\n",
        "    pred_log_probs = log_probs[:, :-1].gather(dim=-1, index=tokens[:, 1:].unsqueeze(-1)).squeeze(-1)\n",
        "    return -pred_log_probs.mean()\n",
        "loss = lm_cross_entropy_loss(demo_logits, test_tokens)\n",
        "print(loss)\n",
        "print(\"Loss as average prob\", (-loss).exp())\n",
        "print(\"Loss as 'uniform over this many variables'\", (loss).exp())\n",
        "print(\"Uniform loss over the vocab\", math.log(demo_gpt2.cfg.d_vocab))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnhVdsOGpqIz"
      },
      "source": [
        "We can also greedily generate text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSeN8C0JpqIz",
        "outputId": "acb88dc1-0296-41d6-a767-49ea12a51ba6",
        "colab": {
          "referenced_widgets": [
            "a40883b71ac94ec9a2f972bad3dc31d1",
            "c99ff910099042879929c551b19fe5bf",
            "fd525dcc90b74dcd82d09073c99bff40",
            "130d04215446430aba5f83fa60470286",
            "b0ad3c6837ae4bc591c44d5d3588ccfb",
            "e1ca9f5dbc2549158cac06947d577c03",
            "a9d5cfb0d86c48edbea74f6c103d9337",
            "ebd369d604e84baa9c70c646b2eb1a97",
            "1e4a43e4b391477b8841e9b7ca27e4b6",
            "962d127ee4074508a10b9d70948e57e9",
            "95cbd680d3e44fa6ae7a83d48d9852c3"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a40883b71ac94ec9a2f972bad3dc31d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized_resid_mid: torch.Size([1, 105, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 105, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 105, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 105, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 105, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 105, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 105, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 105, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 105, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 105, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 105, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 105, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 106, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 107, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 108, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 109, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 110, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 111, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 112, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 113, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 114, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 115, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 116, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 117, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 118, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Normalized_resid_mid: torch.Size([1, 119, 768])\n",
            "Breaking News: President Trump has been impeached by the House of Representatives for abuse of power and obstruction of Congress. The vote was 230 to 197, with 10 Republicans joining all Democrats in voting to impeach. The president is now only the third in American history to be impeached, and the first to be impeached twice. The House will now send the articles of impeachment to the Senate, where a trial will be held to determine whether to remove the president from office. The Senate is expected to begin the trial on,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n"
          ]
        }
      ],
      "source": [
        "test_string = \"Breaking News: President Trump has been impeached by the House of Representatives for abuse of power and obstruction of Congress. The vote was 230 to 197, with 10 Republicans joining all Democrats in voting to impeach. The president is now only the third in American history to be impeached, and the first to be impeached twice. The House will now send the articles of impeachment to the Senate, where a trial will be held to determine whether to remove the president from office. The Senate is expected to begin the trial on\"\n",
        "for i in tqdm.tqdm(range(100)):\n",
        "    test_tokens = reference_gpt2.to_tokens(test_string)\n",
        "    demo_logits = demo_gpt2(test_tokens)\n",
        "    test_string += reference_gpt2.tokenizer.decode(demo_logits[-1, -1].argmax())\n",
        "print(test_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question No.: 2"
      ],
      "metadata": {
        "id": "w3iSyWczSs1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rotary Positional Embedding"
      ],
      "metadata": {
        "id": "C3skMH0OvIcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def apply_rotary_pos_emb(x, sincos):\n",
        "    # Extract sine and cosine values from the tuple\n",
        "    sin, cos = map(lambda t: t.repeat_interleave(2, dim=-1), sincos)\n",
        "\n",
        "    # Apply rotary positional embeddings to the input tensor\n",
        "    result = (x * cos) + (torch.roll(x, shifts=1, dims=-1) * sin)\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "GtbeERM5SxWX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group Query Attention"
      ],
      "metadata": {
        "id": "MbaBHnXFvTgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def group_query_attention(query, key, value, num_groups):\n",
        "    # Split queries into groups\n",
        "    group_size = query.size(2) // num_groups\n",
        "    query_groups = query.view(*query.size()[:2], num_groups, group_size)\n",
        "\n",
        "    # Perform attention within each group\n",
        "    attention_output = []\n",
        "    for i in range(num_groups):\n",
        "        group_attn_output = scaled_dot_product_attention(query_groups[:,:,i,:], key, value)\n",
        "        attention_output.append(group_attn_output)\n",
        "\n",
        "\n",
        "    return torch.cat(attention_output, dim=-1)\n"
      ],
      "metadata": {
        "id": "-k2OTFUWvSOX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sliding Window Attention"
      ],
      "metadata": {
        "id": "wJmjIeshvu4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sliding_window_attention(query, key, value, window_size):\n",
        "    # Assume query, key, and value are all the same size for simplicity\n",
        "    batch_size, seq_length, dim = query.size()\n",
        "    attention_scores = torch.empty((batch_size, seq_length, window_size), device=query.device)\n",
        "\n",
        "    # Compute attention scores for a sliding window\n",
        "    for i in range(seq_length):\n",
        "        start = max(0, i - window_size // 2)\n",
        "        end = min(seq_length, i + window_size // 2 + 1)\n",
        "        attention_scores[:, i, :end-start] = torch.bmm(query[:, i:i+1, :], key[:, start:end, :].transpose(1, 2))\n",
        "\n",
        "    # Apply softmax to get attention probabilities\n",
        "    attention_probs = torch.nn.functional.softmax(attention_scores, dim=-1)\n",
        "\n",
        "    # Compute weighted sum to get the attention output\n",
        "    attention_output = torch.bmm(attention_probs, value[:, start:end, :])\n",
        "    return attention_output"
      ],
      "metadata": {
        "id": "aYdpe672vz1g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 3"
      ],
      "metadata": {
        "id": "o9pzVTy8v6RE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Single GPU Training"
      ],
      "metadata": {
        "id": "WIWVAvHPwAOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Assuming model, dataset, optimizer, and loss function are defined\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch in dataloader:\n",
        "        inputs, targets = batch\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_function(outputs, targets)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "QDWbEmcAxl5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Distributed Data Parallel (DDP)"
      ],
      "metadata": {
        "id": "0k7OWTQvwgeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.distributed as dist\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "import torch.utils.data.distributed\n",
        "\n",
        "# Setup (before the loop)\n",
        "dist.init_process_group(backend='nccl')\n",
        "model = model.to(device)\n",
        "model = DDP(model, device_ids=[local_rank], output_device=local_rank)\n",
        "\n",
        "# Adjust dataloader for distributed training\n",
        "sampler = torch.utils.data.distributed.DistributedSampler(dataset)\n",
        "dataloader = DataLoader(dataset, sampler=sampler, ...)"
      ],
      "metadata": {
        "id": "DUsXcN3QxwaU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a40883b71ac94ec9a2f972bad3dc31d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c99ff910099042879929c551b19fe5bf",
              "IPY_MODEL_fd525dcc90b74dcd82d09073c99bff40",
              "IPY_MODEL_130d04215446430aba5f83fa60470286"
            ],
            "layout": "IPY_MODEL_b0ad3c6837ae4bc591c44d5d3588ccfb"
          }
        },
        "c99ff910099042879929c551b19fe5bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1ca9f5dbc2549158cac06947d577c03",
            "placeholder": "​",
            "style": "IPY_MODEL_a9d5cfb0d86c48edbea74f6c103d9337",
            "value": "100%"
          }
        },
        "fd525dcc90b74dcd82d09073c99bff40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebd369d604e84baa9c70c646b2eb1a97",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e4a43e4b391477b8841e9b7ca27e4b6",
            "value": 100
          }
        },
        "130d04215446430aba5f83fa60470286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_962d127ee4074508a10b9d70948e57e9",
            "placeholder": "​",
            "style": "IPY_MODEL_95cbd680d3e44fa6ae7a83d48d9852c3",
            "value": " 100/100 [01:10&lt;00:00,  1.65it/s]"
          }
        },
        "b0ad3c6837ae4bc591c44d5d3588ccfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1ca9f5dbc2549158cac06947d577c03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9d5cfb0d86c48edbea74f6c103d9337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebd369d604e84baa9c70c646b2eb1a97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e4a43e4b391477b8841e9b7ca27e4b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "962d127ee4074508a10b9d70948e57e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95cbd680d3e44fa6ae7a83d48d9852c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}